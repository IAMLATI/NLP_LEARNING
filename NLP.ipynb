{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz6i0VvIDX+fm+/wE3SDdY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAMLATI/NLP_LEARNING/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e94AttYwhEN5",
        "outputId": "c96e575d-fddd-4b36-8456-5d6f3ab59be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = '''\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "Artificial intelligence is transforming industries worldwide.\n",
        "Data science combines statistics, programming, and domain expertise.\n",
        "Natural language processing enables machines to understand human language.\n",
        "Python is a popular programming language for machine learning.\n",
        "Cloud computing offers scalable resources for businesses.\n",
        "Cybersecurity is essential in the digital age.\n",
        "Machine learning models improve with more data and better algorithms.\n",
        "Healthcare technology is advancing rapidly with AI integration.\n",
        "Big data analytics helps organizations make informed decisions.\n",
        "'''"
      ],
      "metadata": {
        "id": "uGmnhr0QhLBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Pa47Dwjs4w",
        "outputId": "807a3ebe-5eef-4b40-eb01-61788dd204e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The quick brown fox jumps over the lazy dog.\n",
            "Artificial intelligence is transforming industries worldwide.\n",
            "Data science combines statistics, programming, and domain expertise.\n",
            "Natural language processing enables machines to understand human language.\n",
            "Python is a popular programming language for machine learning.\n",
            "Cloud computing offers scalable resources for businesses.\n",
            "Cybersecurity is essential in the digital age.\n",
            "Machine learning models improve with more data and better algorithms.\n",
            "Healthcare technology is advancing rapidly with AI integration.\n",
            "Big data analytics helps organizations make informed decisions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "0dFjxwn5j5vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBq0WqYAkMeI",
        "outputId": "82261df9-4f9b-45a3-d481-a2e8838a601e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "dYS0C8tSj_hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_OAYZmik7nL",
        "outputId": "a6cd0446-8ad9-4c51-a76c-0eba5b536216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumps',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog',\n",
              " '.',\n",
              " 'Artificial',\n",
              " 'intelligence',\n",
              " 'is',\n",
              " 'transforming',\n",
              " 'industries',\n",
              " 'worldwide',\n",
              " '.',\n",
              " 'Data',\n",
              " 'science',\n",
              " 'combines',\n",
              " 'statistics',\n",
              " ',',\n",
              " 'programming',\n",
              " ',',\n",
              " 'and',\n",
              " 'domain',\n",
              " 'expertise',\n",
              " '.',\n",
              " 'Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'enables',\n",
              " 'machines',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'human',\n",
              " 'language',\n",
              " '.',\n",
              " 'Python',\n",
              " 'is',\n",
              " 'a',\n",
              " 'popular',\n",
              " 'programming',\n",
              " 'language',\n",
              " 'for',\n",
              " 'machine',\n",
              " 'learning',\n",
              " '.',\n",
              " 'Cloud',\n",
              " 'computing',\n",
              " 'offers',\n",
              " 'scalable',\n",
              " 'resources',\n",
              " 'for',\n",
              " 'businesses',\n",
              " '.',\n",
              " 'Cybersecurity',\n",
              " 'is',\n",
              " 'essential',\n",
              " 'in',\n",
              " 'the',\n",
              " 'digital',\n",
              " 'age',\n",
              " '.',\n",
              " 'Machine',\n",
              " 'learning',\n",
              " 'models',\n",
              " 'improve',\n",
              " 'with',\n",
              " 'more',\n",
              " 'data',\n",
              " 'and',\n",
              " 'better',\n",
              " 'algorithms',\n",
              " '.',\n",
              " 'Healthcare',\n",
              " 'technology',\n",
              " 'is',\n",
              " 'advancing',\n",
              " 'rapidly',\n",
              " 'with',\n",
              " 'AI',\n",
              " 'integration',\n",
              " '.',\n",
              " 'Big',\n",
              " 'data',\n",
              " 'analytics',\n",
              " 'helps',\n",
              " 'organizations',\n",
              " 'make',\n",
              " 'informed',\n",
              " 'decisions',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING\n",
        "\n",
        "PORTER STEMMING"
      ],
      "metadata": {
        "id": "IqmhKlp1drdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "Kc3Bolslc2uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming = PorterStemmer()"
      ],
      "metadata": {
        "id": "xcnsg214fKrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "words = [\n",
        "    \"running\",\n",
        "    \"runs\",\n",
        "    \"runner\",\n",
        "    \"played\",\n",
        "    \"playing\",\n",
        "    \"plays\",\n",
        "    \"happiness\",\n",
        "    \"happily\",\n",
        "    \"happier\",\n",
        "    \"studies\",\n",
        "    \"studying\",\n",
        "    \"studied\",\n",
        "    \"organization\",\n",
        "    \"organized\",\n",
        "    \"organizing\",\n",
        "    \"cats\",\n",
        "    \"dogs\",\n",
        "    \"boxes\",\n",
        "    \"quickly\",\n",
        "    \"quickest\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "O1Ij5FozfLi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+'----->'+ stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSoRAj9veppW",
        "outputId": "34e5e6b8-d7c5-4c4e-c95b-7739abf11492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running----->run\n",
            "runs----->run\n",
            "runner----->runner\n",
            "played----->play\n",
            "playing----->play\n",
            "plays----->play\n",
            "happiness----->happi\n",
            "happily----->happili\n",
            "happier----->happier\n",
            "studies----->studi\n",
            "studying----->studi\n",
            "studied----->studi\n",
            "organization----->organ\n",
            "organized----->organ\n",
            "organizing----->organ\n",
            "cats----->cat\n",
            "dogs----->dog\n",
            "boxes----->box\n",
            "quickly----->quickli\n",
            "quickest----->quickest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import RegexpStemmer"
      ],
      "metadata": {
        "id": "Irtim6GZsEki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min = 4)"
      ],
      "metadata": {
        "id": "3kMoLmBFsNzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+'---->'+ reg_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVa4RX7hsu-s",
        "outputId": "160bb019-d3d7-4365-d46b-8c3055256b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running---->runn\n",
            "runs---->run\n",
            "runner---->runner\n",
            "played---->played\n",
            "playing---->play\n",
            "plays---->play\n",
            "happiness---->happines\n",
            "happily---->happily\n",
            "happier---->happier\n",
            "studies---->studie\n",
            "studying---->study\n",
            "studied---->studied\n",
            "organization---->organization\n",
            "organized---->organized\n",
            "organizing---->organiz\n",
            "cats---->cat\n",
            "dogs---->dog\n",
            "boxes---->boxe\n",
            "quickly---->quickly\n",
            "quickest---->quickest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SNOWBALL STEMMER"
      ],
      "metadata": {
        "id": "3X_3FzpgtsDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "eaOH8KrKtrLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowballstem = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "rmYpN9xVtzyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+'---->'+ snowballstem.stem(word))"
      ],
      "metadata": {
        "id": "pB5QvnGkt83c",
        "outputId": "d3c8e6be-93f4-4992-c691-c9cf8d26b909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running---->run\n",
            "runs---->run\n",
            "runner---->runner\n",
            "played---->play\n",
            "playing---->play\n",
            "plays---->play\n",
            "happiness---->happi\n",
            "happily---->happili\n",
            "happier---->happier\n",
            "studies---->studi\n",
            "studying---->studi\n",
            "studied---->studi\n",
            "organization---->organ\n",
            "organized---->organ\n",
            "organizing---->organ\n",
            "cats---->cat\n",
            "dogs---->dog\n",
            "boxes---->box\n",
            "quickly---->quick\n",
            "quickest---->quickest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "d_gbyqgrOW0O"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}